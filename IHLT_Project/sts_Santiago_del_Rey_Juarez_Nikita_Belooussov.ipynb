{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2jMkKylwoeys"
   },
   "source": [
    "# IHLT final project - Semantic Textual Similarity\n",
    "Nikita Belooussov and Santiago del Rey Juárez\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "In this project, we conducted a workshop included in SemEval (Semantic Evaluation Exercises) which are a series of workshops that have the main aim of the evaluation and comparison of semantic analysis systems. The data and corpora provided by them have become a ’de facto’ set of benchmarks for the NLP community.\n",
    "\n",
    "Our particular task was to conduct Semantic Textual Similarity (STS), also known as paraphrases detection. A paraphrase between two sentences or texts is when both have the same meaning using different words. The task consists in given two pairs of sentences, provide a similarity value between them.\n",
    "\n",
    "In this task, Pearson correlation is used for comparison purposes.\n",
    "\n",
    "The rest of the notebook is structured as follows. In Section 2 we describe the data pre-processing steps and present the metrics used to detect paraphrasing. In Section 3 we explain the models used and how we proceeded to obtain our results. Finally, in Section 4 we expose our conclusions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Settings\n",
    "Choose if you want to run the code with it trying to find the best optimization, or have the optimization that was hard coded in based off of previous tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize = int(input(\"Do you want to optimize code?\\n0) No use previous setting\\n1) Yes optimize\\n Input:\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2. Data pre-processing and feature extraction\n",
    "In this section, we explain the functions created to read and pre-process the data. Then, we describe the similarity metrics we extracted from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contractions in c:\\users\\nbelo\\anaconda3\\envs\\ihlt2\\lib\\site-packages (0.0.58)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in c:\\users\\nbelo\\anaconda3\\envs\\ihlt2\\lib\\site-packages (from contractions) (0.0.21)\n",
      "Requirement already satisfied: pyahocorasick in c:\\users\\nbelo\\anaconda3\\envs\\ihlt2\\lib\\site-packages (from textsearch>=0.0.21->contractions) (1.4.2)\n",
      "Requirement already satisfied: anyascii in c:\\users\\nbelo\\anaconda3\\envs\\ihlt2\\lib\\site-packages (from textsearch>=0.0.21->contractions) (0.3.0)\n",
      "Requirement already satisfied: num2words in c:\\users\\nbelo\\anaconda3\\envs\\ihlt2\\lib\\site-packages (0.5.10)\n",
      "Requirement already satisfied: docopt>=0.6.2 in c:\\users\\nbelo\\anaconda3\\envs\\ihlt2\\lib\\site-packages (from num2words) (0.6.2)\n"
     ]
    }
   ],
   "source": [
    "# requires visual studios builder from https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
    "!pip install contractions\n",
    "!pip install num2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Nv-sb04fXE1",
    "outputId": "a35cc345-8843-4a63-f109-6db1d60463c9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nbelo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nbelo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\nbelo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nbelo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet_ic to\n",
      "[nltk_data]     C:\\Users\\nbelo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet_ic is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import pickle\n",
    "import string\n",
    "\n",
    "import contractions\n",
    "import nltk\n",
    "import num2words\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from joblib import dump\n",
    "from nltk import BigramCollocationFinder\n",
    "from nltk import TrigramCollocationFinder\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet_ic\n",
    "from nltk.corpus.reader import WordNetError\n",
    "from nltk.metrics import jaccard_distance\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('wordnet_ic')\n",
    "\n",
    "contractions.add('U.S.', 'United States')\n",
    "contractions.add('U.S.A', 'United States of America')\n",
    "contractions.add('E.U.', 'European Union')\n",
    "\n",
    "#if this does not work run python -m spacy download en in terminal and restart the program running the code\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "brown_ic = wordnet_ic.ic('ic-brown.dat')\n",
    "semcor_ic = wordnet_ic.ic('ic-semcor.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Data-preprocessing\n",
    "**Read files**\n",
    "\n",
    "The `read_file` function simply reads the data from the file path provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def read_file(file_path):\n",
    "    return pd.read_csv(file_path, sep='\\t', lineterminator='\\n', header=None,\n",
    "                       quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Remove contractions**\n",
    "The `expand_contractions` function is used to remove the contractions that might appear in the sentences. For example, \"he's late\" would be expanded to \"he is late\". With this, we expect to obtain more accurate similarities from the metrics since we are enriching our sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def expand_contractions(s0, s1):\n",
    "    s0 = contractions.fix(s0)\n",
    "    s1 = contractions.fix(s1)\n",
    "    return s0, s1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Change numbers to words**\n",
    "\n",
    "The `changeNums` function is used to replace the numbers in a sentence with their corresponding written form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def changeNums(s0):\n",
    "    s0 = s0.split()\n",
    "    new_s0 = []\n",
    "    for i in s0:\n",
    "        if i.isdigit():\n",
    "            new_s0.append(num2words.num2words(i))\n",
    "        else:\n",
    "            new_s0.append(i)\n",
    "    s0 = ' '.join(new_s0)\n",
    "    return s0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Tokenize**\n",
    "\n",
    "The `tokenize` function splits a sentence into tokens. In addition, it changes the whole sentence to lowercase and removes both punctuation symbols (i.e. !\"#$%&'()*+, -./:;<=>?@[]^_`{|}~) and English stopwords (e.g. “i”, “he”, “the”).\n",
    "\n",
    "The `name_entity_tokenization` does the same as the `tokenize` function with the addition of joining tokens that belong to the same named entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "punct = string.punctuation\n",
    "\n",
    "\n",
    "def tokenize(sentence):\n",
    "    return [w.lower() for w in nltk.word_tokenize(sentence) if\n",
    "            not all(c in punct for c in w) and w.lower() not in stopwords.words('english')]\n",
    "\n",
    "\n",
    "def name_entity_tokenization(sentence):\n",
    "    doc = nlp(sentence.lower())\n",
    "    with doc.retokenize() as retokenizer:\n",
    "        tokens = [token for token in doc]\n",
    "        for ent in doc.ents:\n",
    "            retokenizer.merge(doc[ent.start:ent.end],\n",
    "                              attrs={\"LEMMA\": \" \".join([tokens[i].text for i in range(ent.start, ent.end)])})\n",
    "    s0_ne = [token.text for token in doc]\n",
    "    return s0_ne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lemmatize**\n",
    "\n",
    "The `lemmatize_sentence` function is used to extract the lemmas from a tokenized sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "wnl = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def lemmatize(pair):\n",
    "    if pair[1][0] in {'N', 'V', 'J', 'R'}:  #N- noun, V- verb, J- adjective, R-adverb\n",
    "        if pair[1][\n",
    "            0] == 'J':  #this is used due to wordnet using a different label for adjectives than one given by nltk\n",
    "            return wnl.lemmatize(pair[0].lower(), pos=wordnet.ADJ)\n",
    "        return wnl.lemmatize(pair[0].lower(), pos=pair[1][0].lower())\n",
    "    return pair[0]\n",
    "\n",
    "\n",
    "def lemmatize_sentence(words):\n",
    "    pairs = nltk.pos_tag(words)\n",
    "    lemmas = [lemmatize(pair) for pair in pairs]\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Jaccard similarity**\n",
    "\n",
    "The `jaccard_similarity` function computes the Jaccard similarity between two lists of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def jaccard_similarity(words0, words1):\n",
    "    return 1 - jaccard_distance(set(words0), set(words1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "**Synset similarity**\n",
    "\n",
    "The `synset similarity` function is used to compute the similarity between two lemmatized sentences using Path, Wu-Palmer, Leacock-Chodorow, Lin or Resnik methods to obtain the synset similarity. To compute the similarity of the whole sentence, we calculate the maximum synset similarity of each lemma in the first sentence with all the lemmas in the second. Then, we compute the mean similarity of the sentence using the maximums found. In addition, we do the same the other way around since the results are different when comparing the second sentence with the first. Finally, we return the synset similarity as the mean of the two sentences means.\n",
    "\n",
    "Since the computation of all the possible synset combinations is quite time consuming, we use a dictionary to store their results, avoiding the need of computing them each time. Moreover, we save the dictionary in a pickle file for future executions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_wordnet_similarity(s0, s1, method, ic):\n",
    "    if s0 is not None and s1 is not None:\n",
    "        if method == 'path':\n",
    "            return s0.path_similarity(s1)\n",
    "        elif method == 'wup':\n",
    "            return s0.wup_similarity(s1)\n",
    "        elif s0.pos() == s1.pos():\n",
    "            if method == \"lch\":\n",
    "                return s0.lch_similarity(s1)\n",
    "            elif ic is None:\n",
    "                raise ValueError(\"ic parameter is missing\")\n",
    "            elif method == \"lin\":\n",
    "                try:\n",
    "                    return s0.lin_similarity(s1, ic)\n",
    "                except WordNetError:\n",
    "                    return None\n",
    "            elif method == 'res':\n",
    "                try:\n",
    "                    return s0.res_similarity(s1, ic)\n",
    "                except WordNetError:\n",
    "                    return None\n",
    "            else:\n",
    "                return None\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "# Dictionary used to store already computed synsets\n",
    "try:\n",
    "    with open('synset_dic.pkl', 'rb') as file:\n",
    "        computed_synsets = pickle.load(file)\n",
    "except IOError:\n",
    "    computed_synsets = {}\n",
    "\n",
    "\n",
    "def max_similarity(s0, s1, method, ic):\n",
    "    if s0 == s1:\n",
    "        return 1\n",
    "\n",
    "    if (s0, s1, method) in computed_synsets:\n",
    "        return computed_synsets[(s0, s1, method)]\n",
    "\n",
    "    synsets0 = wordnet.synsets(s0)\n",
    "    synsets1 = wordnet.synsets(s1)\n",
    "\n",
    "    similarities = []\n",
    "    for syn0 in synsets0:\n",
    "        for syn1 in synsets1:\n",
    "            similarity = get_wordnet_similarity(syn0, syn1, method, ic)\n",
    "            if similarity is not None:\n",
    "                similarities.append(similarity)\n",
    "\n",
    "    if len(similarities) > 0:\n",
    "        max_sim = max(similarities)\n",
    "        computed_synsets[(s0, s1, method)] = max_sim\n",
    "        return max_sim\n",
    "    else:\n",
    "        computed_synsets[(s0, s1, method)] = 0\n",
    "        return 0\n",
    "\n",
    "\n",
    "def mean_simimilarity(lemmas0, lemmas1, method, ic):\n",
    "    similarity_sum = 0\n",
    "    for l0 in lemmas0:\n",
    "        similarity_sum += max([max_similarity(l0, l1, method, ic) for l1 in lemmas1])\n",
    "    return similarity_sum / len(lemmas0)\n",
    "\n",
    "\n",
    "def synset_similarity(lemmas0, lemmas1, method, ic=None):\n",
    "    mean_sim0 = mean_simimilarity(lemmas0, lemmas1, method, ic)\n",
    "    mean_sim1 = mean_simimilarity(lemmas1, lemmas0, method, ic)\n",
    "\n",
    "    if mean_sim0 > 0 or mean_sim1 > 0:\n",
    "        return mean_sim0 + mean_sim1 / 2\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Lesk similarity**\n",
    "\n",
    "The `lesk_similarity` function uses the Lesk algorithm to do word sense disambiguation in each sentence and then computes the Jaccard similarity between the disambiguated sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def lesk_similarity(words0, words1):\n",
    "    w0_pos = nltk.pos_tag(words0)\n",
    "    w1_pos = nltk.pos_tag(words1)\n",
    "\n",
    "    s0_lesk = []\n",
    "    for i in range(len(w0_pos)):\n",
    "        if w0_pos[i][1][0] in {'N', 'V', 'J', 'R'}:  #N- noun, V- verb, J- adjective, R-adverb\n",
    "            if w0_pos[i][1][\n",
    "                0] == 'J':  #this is used due to wordnet using a different label for adjectives than one given by nltk\n",
    "                s0_lesk.append(nltk.wsd.lesk(words0, w0_pos[i][0], pos=wordnet.ADJ))\n",
    "            else:\n",
    "                s0_lesk.append(nltk.wsd.lesk(words0, w0_pos[i][0], pos=w0_pos[i][1][0].lower()))\n",
    "\n",
    "    s1_lesk = []\n",
    "    for i in range(len(w1_pos)):\n",
    "        if w1_pos[i][1][0] in {'N', 'V', 'J', 'R'}:  #N- noun, V- verb, J- adjective, R-adverb\n",
    "            if w1_pos[i][1][\n",
    "                0] == 'J':  #this is used due to wordnet using a different label for adjectives than one given by nltk\n",
    "                s1_lesk.append(nltk.wsd.lesk(words1, w1_pos[i][0], pos=wordnet.ADJ))\n",
    "            else:\n",
    "                s1_lesk.append(nltk.wsd.lesk(words1, w1_pos[i][0], pos=w1_pos[i][1][0].lower()))\n",
    "\n",
    "    return jaccard_similarity(s0_lesk, s1_lesk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Synonyms similarity**\n",
    "\n",
    "The `synonyms_similarity` function computes the similarity of two lists of lemmas based on the number of shared synsets for the whole list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synonyms_similarity(lemmas0, lemmas1):\n",
    "    if len(lemmas1) < len(lemmas0):\n",
    "        lemmas0, lemmas1 = lemmas1, lemmas0\n",
    "\n",
    "    synonyms1 = []\n",
    "    synonyms2 = []\n",
    "    for i in lemmas0:\n",
    "        synonyms1 = [*synonyms1, *wordnet.synsets(i)]\n",
    "    for i in lemmas1:\n",
    "        synonyms2 = [*synonyms2, *wordnet.synsets(i)]\n",
    "\n",
    "    count = 0\n",
    "    for i in synonyms1:\n",
    "        if i in synonyms2:\n",
    "            count = count + 1\n",
    "    if (len(synonyms1) != 0) and (len(synonyms2) != 0):\n",
    "        return count / len(synonyms1)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**TF-IDF and cosine**\n",
    "\n",
    "The `tf_similarity` function computes the cosine similarity between two lists of words. Moreover, to improve the accuracy it uses TF-IDF to do feature extraction and only use the most important words when computing the similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def tf_similarity(s0, s1):\n",
    "    # Generate the tf-idf vectors for the corpus\n",
    "    words0 = ' '.join([str(elem) for elem in s0])\n",
    "    words1 = ' '.join([str(elem) for elem in s1])\n",
    "\n",
    "    tfvec = TfidfVectorizer()\n",
    "    tfidf_matrix = tfvec.fit_transform([words0, words1])\n",
    "\n",
    "    return cosine_similarity(tfidf_matrix, tfidf_matrix)[0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**N-Gram similarity**\n",
    "\n",
    "The n-gram similarity functions compare how similar are two lists of words by counting the number of shared n-grams. Particularly, we use unigrams, bigrams and trigrams. Moreover, for the bigrams and trigrams, we also return the Jaccard similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def unigram_similarity(words0, words1):\n",
    "    count = 0\n",
    "    for w in words0:\n",
    "        count += min(words0.count(w), words1.count(w))\n",
    "\n",
    "    if len(words1) > 0 or len(words1) > 0:\n",
    "        return 2 * count / (len(words0) + len(words0))\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def bigram_similarity(words0, words1):\n",
    "    finder0 = BigramCollocationFinder.from_words(words0)\n",
    "    finder1 = BigramCollocationFinder.from_words(words1)\n",
    "\n",
    "    # We get the bigrams of first sentence and its frequency\n",
    "    bigrams0 = []\n",
    "    freq0 = []\n",
    "    for b0 in finder0.ngram_fd.items():\n",
    "        bigrams0.append(b0[0])\n",
    "        freq0.append(b0[1])\n",
    "\n",
    "    # We get the bigrams of second sentence and its frequency\n",
    "    bigrams1 = []\n",
    "    freq1 = []\n",
    "    for b0 in finder1.ngram_fd.items():\n",
    "        bigrams1.append(b0[0])\n",
    "        freq1.append(b0[1])\n",
    "\n",
    "    count = 0\n",
    "    for i in range(len(bigrams0)):\n",
    "        if bigrams0[i] in bigrams1:\n",
    "            # Count number of same bigrams\n",
    "            count += min(freq0[i], freq1[bigrams1.index(bigrams0[i])])\n",
    "\n",
    "    if len(words0) > 0 or len(words1) > 0:\n",
    "        if len(bigrams0) > 0 or len(bigrams1) > 0:\n",
    "            return 2 * count / (len(words0) + len(words1)), jaccard_similarity(bigrams0, bigrams1)\n",
    "        else:\n",
    "            return 2 * count / (len(words0) + len(words1)), 0\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def trigram_similarity(words0, words1):\n",
    "    finder0 = TrigramCollocationFinder.from_words(words0)\n",
    "    finder1 = TrigramCollocationFinder.from_words(words1)\n",
    "\n",
    "    # We get the trigrams of first sentence and its frequency\n",
    "    trigrams0 = []\n",
    "    freq0 = []\n",
    "    for t0 in finder0.ngram_fd.items():\n",
    "        trigrams0.append(t0[0])\n",
    "        freq0.append(t0[1])\n",
    "\n",
    "    # We get the trigrams of second sentence and its frequency\n",
    "    trigrams1 = []\n",
    "    freq1 = []\n",
    "    for t1 in finder1.ngram_fd.items():\n",
    "        trigrams1.append(t1[0])\n",
    "        freq1.append(t1[1])\n",
    "\n",
    "    count = 0\n",
    "    for i in range(len(trigrams0)):\n",
    "        if trigrams0[i] in trigrams1:\n",
    "            # Count number of same trigrams\n",
    "            count += min(freq0[i], freq1[trigrams1.index(trigrams0[i])])\n",
    "\n",
    "    if len(words0) > 0 or len(words1) > 0:\n",
    "        if len(trigrams0) > 0 or len(trigrams1) > 0:\n",
    "            return 2 * count / (len(words0) + len(words1)), jaccard_similarity(trigrams0, trigrams1)\n",
    "        else:\n",
    "            return 2 * count / (len(words0) + len(words1)), 0\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Length difference**\n",
    "\n",
    "The `length_difference` function computes the length difference between two lists of words. We normalize the results by dividing the difference by the maximum length. Note that in this metric the closer to 0 the more similar the two lists are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def length_difference(words0, words1):\n",
    "    return abs(len(words0) - len(words1)) / max(len(words0), len(words1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Extract features**\n",
    "\n",
    "The `extract_features` function receives a list of pairs of sentences and applies all the functions detailed above. First, it pre-processes each sentence in order to change the numbers to words, expand contractions, and so on. Then, it computes, for each pair of sentences, all the similarities implemented and stores them in a list of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "N_SYMBOLS = 50\n",
    "\n",
    "\n",
    "def extract_features(x):\n",
    "    features = []\n",
    "    n_samples = x.shape[0]\n",
    "    perc = round(0.02 * n_samples)\n",
    "    counter = 0\n",
    "    progress = 0\n",
    "    for sentence_0, sentence_1 in x:\n",
    "        sentence_0 = changeNums(sentence_0)\n",
    "        sentence_1 = changeNums(sentence_1)\n",
    "        sentence_0, sentence_1 = expand_contractions(sentence_0, sentence_1)\n",
    "        words0 = tokenize(sentence_0)\n",
    "        words1 = tokenize(sentence_1)\n",
    "        s0_lemmas = lemmatize_sentence(words0)\n",
    "        s1_lemmas = lemmatize_sentence(words1)\n",
    "        s0_ne = name_entity_tokenization(sentence_0)\n",
    "        s1_ne = name_entity_tokenization(sentence_1)\n",
    "        bigram_w_count, bigram_w_jc = bigram_similarity(words0, words1)\n",
    "        bigram_l_count, bigram_l_jc = bigram_similarity(s0_lemmas, s1_lemmas)\n",
    "        trigram_w_count, trigram_w_jc = trigram_similarity(words0, words1)\n",
    "        trigram_l_count, trigram_l_jc = trigram_similarity(s0_lemmas, s1_lemmas)\n",
    "\n",
    "        features.append([\n",
    "            jaccard_similarity(words0, words1),\n",
    "            jaccard_similarity(s0_lemmas, s1_lemmas),\n",
    "            jaccard_similarity(s0_ne, s1_ne),\n",
    "            tf_similarity(words0, words1),\n",
    "            tf_similarity(s0_lemmas, s1_lemmas),\n",
    "            tf_similarity(s0_ne, s1_ne),\n",
    "            synset_similarity(s0_lemmas, s1_lemmas, 'path'),\n",
    "            synset_similarity(s0_lemmas, s1_lemmas, 'lch'),\n",
    "            synset_similarity(s0_lemmas, s1_lemmas, 'wup'),\n",
    "            synset_similarity(s0_lemmas, s1_lemmas, 'lin', semcor_ic),\n",
    "            synset_similarity(s0_lemmas, s1_lemmas, 'res', semcor_ic),\n",
    "            lesk_similarity(words0, words1),\n",
    "            unigram_similarity(words0, words1),\n",
    "            unigram_similarity(s0_lemmas, s1_lemmas),\n",
    "            bigram_w_count,\n",
    "            bigram_w_jc,\n",
    "            bigram_l_count,\n",
    "            bigram_l_jc,\n",
    "            trigram_w_count,\n",
    "            trigram_w_jc,\n",
    "            trigram_l_count,\n",
    "            trigram_l_jc,\n",
    "            synonyms_similarity(s0_lemmas, s1_lemmas),\n",
    "            length_difference(s0_lemmas, s1_lemmas)\n",
    "        ])\n",
    "\n",
    "        progress = print_progress(counter, perc, progress)\n",
    "        counter += 1\n",
    "\n",
    "    print()\n",
    "    return np.array(features, dtype=np.float64)\n",
    "\n",
    "\n",
    "def print_progress(counter, perc, progress):\n",
    "    if (counter % perc) == 0:\n",
    "        print('<' + '#' * progress + '.' * (N_SYMBOLS - progress) + '>', end='\\r')\n",
    "        return progress + 1\n",
    "    return progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3. Models\n",
    "\n",
    "This is the main section of the notebook, where we use all the functions previously described to create a feature matrix that we will use to train and test several models, which will be then compared to the gold-standard of the STS workshop by means of the Pearson correlation. Our main goal is to obtain a correlation above **0.7562** in the testing data, which corresponds with the one achieved by the 10th group in the SemEval2012.\n",
    "\n",
    "### Read data and extract features\n",
    "\n",
    "First, we read all the data files provided to us and create four numpy arrays. Two contain the pairs of sentences, one for training and one for testing. The other two arrays correspond to the gold-standard labels for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Read train data\n",
    "dataPath = os.path.join('data', 'train')\n",
    "train_data = None\n",
    "for filename in sorted(os.listdir(dataPath)):\n",
    "    if \"STS.input\" in filename:\n",
    "        data = read_file(os.path.join(dataPath, filename)).to_numpy()\n",
    "        if train_data is None:\n",
    "            train_data = data\n",
    "        else:\n",
    "            train_data = np.concatenate((train_data, data))\n",
    "\n",
    "y_train = None\n",
    "for filename in sorted(os.listdir(dataPath)):\n",
    "    if \"STS.gs\" in filename:\n",
    "        data = read_file(os.path.join(dataPath, filename)).to_numpy()\n",
    "        if y_train is None:\n",
    "            y_train = data\n",
    "        else:\n",
    "            y_train = np.concatenate((y_train, data))\n",
    "\n",
    "y_train = y_train.ravel()\n",
    "\n",
    "##Read test data\n",
    "dataPath = os.path.join('data', 'test-gold')\n",
    "test_data = None\n",
    "for filename in sorted(os.listdir(dataPath)):\n",
    "    if \"STS.input\" in filename:\n",
    "        data = read_file(os.path.join(dataPath, filename)).to_numpy()\n",
    "        if test_data is None:\n",
    "            test_data = data\n",
    "        else:\n",
    "            test_data = np.concatenate((test_data, data))\n",
    "\n",
    "y_test = None\n",
    "for filename in sorted(os.listdir(dataPath)):\n",
    "    if \"STS.gs\" in filename and \"ALL\" not in filename:\n",
    "        data = read_file(os.path.join(dataPath, filename)).to_numpy()\n",
    "        if y_test is None:\n",
    "            y_test = data\n",
    "        else:\n",
    "            y_test = np.concatenate((y_test, data))\n",
    "\n",
    "y_test = y_test.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Once we have all the training and testing data, we proceed to the feature extraction for each dataset. Two important things we do in this step are; (i) we replace the `np.inf` values that the Resnik similarity might return by the maximum representable number of a `float64` and normalize the column using this new value, (ii) we use `StandardScaler` to bring all the features to the same scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting computation of training data similarities\n",
      "\n",
      "Max value in train features: 1.5e+300\n",
      "Max value in train features after np.inf replacement: 4.93651885416962\n",
      "Finished computation of training data similarities\n",
      "\n",
      "Starting computation of testing data similarities\n",
      "<##################################################>\n",
      "Max value in test features: 1.375e+300\n",
      "Max value in test features after np.inf replacement: 5.4563792395895785\n",
      "Finished computation of testing data similarities\n",
      "\n"
     ]
    }
   ],
   "source": [
    "INF = np.finfo(np.float64).max\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "print('Starting computation of training data similarities')\n",
    "train_features = extract_features(train_data)\n",
    "print('Max value in train features:', train_features.max())\n",
    "# Since Resnik similarity can go up to infinity we set the max possible value to\n",
    "# the maximum representable number in float64.\n",
    "# Then, we divide by the maximum in order to normalize and avoid an overflow when using the StandardScaler\n",
    "train_features[train_features == np.inf] = INF\n",
    "train_features[:, 10] = train_features[:, 10] / INF\n",
    "print('Max value in train features after np.inf replacement:', train_features.max())\n",
    "x_train = np.round(scaler.fit_transform(train_features), 3)\n",
    "print('Finished computation of training data similarities\\n')\n",
    "\n",
    "print('Starting computation of testing data similarities')\n",
    "test_features = extract_features(test_data)\n",
    "print('Max value in test features:', test_features.max())\n",
    "test_features[test_features == np.inf] = INF\n",
    "test_features[:, 10] = test_features[:, 10] / INF\n",
    "print('Max value in test features after np.inf replacement:', test_features.max())\n",
    "x_test = np.round(scaler.fit_transform(test_features), 3)\n",
    "print('Finished computation of testing data similarities\\n')\n",
    "\n",
    "# We save the already computed synset similarities to speed up future runs\n",
    "with open('synset_dic.pkl', 'wb') as file:\n",
    "    pickle.dump(computed_synsets, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor\n",
    "\n",
    "First, we tried to use a Random Forest regressor to detect paraphrasing based on the features we previously extracted. However, the best correlation we could achieve was **0.7324**. These results were not good enough and we decided to try with a different model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "selected_features_svr = [\n",
    "    0,  # jaccard using words\n",
    "    1,  # jaccard using lemmas\n",
    "    2,  # jaccard using NEs\n",
    "    3,  # tf similarity using words\n",
    "    4,  # tf similairty using lemmas\n",
    "    5,  # tf similarity using NEs\n",
    "    6,  # path similarity\n",
    "    7,  # lch similarity\n",
    "    8,  # wup similarity\n",
    "    #  9, # lin semcor similarity\n",
    "    # 10,  # res semcor similarity\n",
    "    # 11,  # lesk similarity\n",
    "    12,  #unigram count using words\n",
    "    13,  #unigram count using lemmas\n",
    "    14,  #bigram count using words\n",
    "    # 15, #bigram jaccard using words\n",
    "    16,  #bigram count using lemmas\n",
    "    # 17, #bigram jaccard using lemmas\n",
    "    18,  #trigram count using words\n",
    "    # 19, #trigram jaccard using words\n",
    "    20,  #trigram count using lemmas\n",
    "    # 21, #trigram jaccard using lemmas\n",
    "    # 22,  #synnonyms\n",
    "    23  #length difference using lemmas\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf = None\n",
    "best_corr_rf = 0\n",
    "best_n = 0\n",
    "best_ms = 0\n",
    "if optimize==1:\n",
    "    for n in np.arange(75, 85):\n",
    "        for ms in np.arange(20, 30):\n",
    "            rf_regr = RandomForestRegressor(n_estimators=n, min_samples_leaf=ms, random_state=72)\n",
    "            rf_regr.fit(x_train[:, selected_features_svr], y_train)\n",
    "    \n",
    "            # Use the forest's predict method on the test data\n",
    "            rf_pred = rf_regr.predict(x_test[:, selected_features_svr])\n",
    "            rf_correlation = pearsonr(rf_pred, y_test)[0]\n",
    "    \n",
    "            if best_corr_rf < rf_correlation:\n",
    "                best_n = n\n",
    "                best_ms = ms\n",
    "                best_corr_rf = rf_correlation\n",
    "                best_rf = rf_regr\n",
    "    \n",
    "    print(f'Best parameters: n_neighbors={best_n}, min_samples_leaf={best_ms}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation using Random Forest Regressor: 0.7346865055983192\n"
     ]
    }
   ],
   "source": [
    "if optimize==1:\n",
    "    rf_pred = best_rf.predict(x_test[:, selected_features_svr])\n",
    "\n",
    "    rf_correlation = pearsonr(rf_pred, y_test)[0]\n",
    "    print(f'Pearson correlation using Random Forest Regressor: {rf_correlation}')\n",
    "else:\n",
    "    rf_regr = RandomForestRegressor(n_estimators=84, min_samples_leaf=20, random_state=72)\n",
    "    rf_regr.fit(x_train[:, selected_features_svr], y_train)\n",
    "    # Use the forest's predict method on the test data\n",
    "    rf_pred = rf_regr.predict(x_test[:, selected_features_svr])\n",
    "    rf_correlation = pearsonr(rf_pred, y_test)[0]   \n",
    "    print(f'Pearson correlation using Random Forest Regressor: {rf_correlation}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### K-Nearest Neighbors Regressor\n",
    "\n",
    "After trying with the Random Forest, we thought of using a K-Nearest Neighbors (KNN) regressor to solve the task at hand. However, after trying several combinations of parameters we were unable to improve our results very much. Concretely, the KNN regressor obtained a correlation of **0.7153**, which is a downgrade compared to the previous model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_knn = None\n",
    "best_knn_corr = 0\n",
    "best_n = 0\n",
    "best_w = None\n",
    "best_m = None\n",
    "if optimize==1:\n",
    "    for n in np.arange(15, 25):\n",
    "        for w in ['uniform', 'distance']:\n",
    "            for m in ['minkowski', 'euclidean', 'manhattan']:\n",
    "                knn_regr = KNeighborsRegressor(n_neighbors=n, weights=w, metric=m)\n",
    "                knn_regr.fit(x_train[:, selected_features_svr], y_train)\n",
    "    \n",
    "                knn_pred = knn_regr.predict(x_test[:, selected_features_svr])\n",
    "    \n",
    "                knn_correlation = pearsonr(knn_pred, y_test)[0]\n",
    "                if best_knn_corr < knn_correlation:\n",
    "                    best_knn = knn_regr\n",
    "                    best_knn_corr = knn_correlation\n",
    "                    best_n = n\n",
    "                    best_w = w\n",
    "                    best_m = m\n",
    "    \n",
    "    print(f'Best parameters: n_neighbors={best_n}, weights={best_w}, metric={best_m}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation using KNN Regressor: 0.7152888696859583\n"
     ]
    }
   ],
   "source": [
    "if optimize==1:\n",
    "    knn_pred = best_knn.predict(x_test[:, selected_features_svr])\n",
    "\n",
    "    knn_correlation = pearsonr(knn_pred, y_test)[0]\n",
    "    print(f'Pearson correlation using KNN Regressor: {knn_correlation}')\n",
    "\n",
    "else:\n",
    "    knn_regr = KNeighborsRegressor(n_neighbors=17, weights=\"distance\", metric=\"minkowski\")\n",
    "    knn_regr.fit(x_train[:, selected_features_svr], y_train)\n",
    "    knn_pred = knn_regr.predict(x_test[:, selected_features_svr])\n",
    "    knn_correlation = pearsonr(knn_pred, y_test)[0]\n",
    "    print(f'Pearson correlation using KNN Regressor: {knn_correlation}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Support Vector Regressor\n",
    "\n",
    "Having failed with the two previous models, we decided to follow the example of some of the participants in the SemEval2012 and chose to use a Support Vector Regression (SVR) model. This time our results improved considerably with respect to the other models used. After trying different combinations of features and finding the optimal hyperparameters for the SVR model we reached a correlation of **0.7524**. However, it was still lower than our goal correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "best_svr = None\n",
    "best_svr_corr = 0\n",
    "best_c = None\n",
    "best_g = None\n",
    "best_e = None\n",
    "best_t = None\n",
    "if optimize==1:\n",
    "    cs = np.linspace(1, 5, 10)\n",
    "    gammas = np.linspace(1e-1, 1, 10)\n",
    "    epsilons = np.linspace(0.1, 1, 10)\n",
    "    tolerances = np.linspace(1e-3, 1, 10)\n",
    "    for c in cs:\n",
    "        for g in gammas:\n",
    "            for e in epsilons:\n",
    "                for t in tolerances:\n",
    "                    svr_regr = SVR(C=c, gamma=g, epsilon=e, tol=t)\n",
    "                    svr_regr.fit(x_train[:, selected_features_svr], y_train)\n",
    "                    svr_pred = svr_regr.predict(x_test[:, selected_features_svr])\n",
    "                    svr_correlation = pearsonr(svr_pred, y_test)[0]\n",
    "    \n",
    "                    if best_svr_corr < svr_correlation:\n",
    "                        best_c = c\n",
    "                        best_g = g\n",
    "                        best_e = e\n",
    "                        best_t = t\n",
    "                        best_svr_corr = svr_correlation\n",
    "                        best_svr = svr_regr\n",
    "    \n",
    "    print(f'Best parameters: C={best_c}, gamma={best_g}, epsilon={best_e}, tol={best_t}')\n",
    "    print(f'Pearson correlation using Support Vector Regressor: {best_svr_corr}')\n",
    "    \n",
    "    if best_svr_corr > 0.7561:\n",
    "        dump(best_svr, 'svr_regr.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation using Support Vector Regressor: 0.7493094722567379\n"
     ]
    }
   ],
   "source": [
    "if optimize==1:\n",
    "    svr_regr = SVR(C=best_c, gamma=best_g, epsilon=best_e, tol=best_t)\n",
    "    svr_regr.fit(x_train[:, selected_features_svr], y_train)\n",
    "    svr_pred = svr_regr.predict(x_test[:, selected_features_svr])\n",
    "    svr_correlation = pearsonr(svr_pred, y_test)[0]\n",
    "    print(f'Pearson correlation using Support Vector Regressor: {svr_correlation}')\n",
    "\n",
    "else:\n",
    "    svr_regr = SVR(C=3.2222222222222223, gamma=0.1, epsilon=0.2, tol=1.0)\n",
    "    svr_regr.fit(x_train[:, selected_features_svr], y_train)\n",
    "    svr_pred = svr_regr.predict(x_test[:, selected_features_svr])\n",
    "    svr_correlation = pearsonr(svr_pred, y_test)[0]\n",
    "    print(f'Pearson correlation using Support Vector Regressor: {svr_correlation}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression\n",
    "\n",
    "Since we were not able to reach any desired results with the aforementioned models, we thought that we could try with a Lasso regression model instead of adding more similarity metrics. This model performed better than the Random Forest and K-Neighbors regressors achieving a correlation coefficient of **0.7266**. However, it performed worse than the SVR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "selected_features_lasso = [\n",
    "    0,  # jaccard using words\n",
    "    1,  # jaccard using lemmas\n",
    "    2,  # jaccard using NEs\n",
    "    3,  # tf similarity using words\n",
    "    4,  # tf similairty using lemmas\n",
    "    5,  # tf similarity using NEs\n",
    "    6,  # path similarity\n",
    "    7,  # lch similarity\n",
    "    8,  # wup similarity\n",
    "    9,  # lin semcor similarity\n",
    "    10,  # res semcor similarity\n",
    "    11,  # lesk similarity\n",
    "    12,  #unigram count using words\n",
    "    13,  #unigram count using lemmas\n",
    "    14,  #bigram count using words\n",
    "    15,  #bigram jaccard using words\n",
    "    16,  #bigram count using lemmas\n",
    "    17,  #bigram jaccard using lemmas\n",
    "    18,  #trigram count using words\n",
    "    19,  #trigram jaccard using words\n",
    "    20,  #trigram count using lemmas\n",
    "    21,  #trigram jaccard using lemmas\n",
    "    22,  #synnonyms\n",
    "    23  #length difference using lemmas\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation using Lasso: 0.7274007132568785\n"
     ]
    }
   ],
   "source": [
    "lasso_regr = Lasso(alpha=4e-3, max_iter=5000)\n",
    "lasso_regr.fit(x_train[:, selected_features_lasso], y_train)\n",
    "lasso_pred = lasso_regr.predict(x_test[:, selected_features_lasso])\n",
    "\n",
    "lasso_correlation = pearsonr(lasso_pred, y_test)[0]\n",
    "print(f'Pearson correlation using Lasso: {lasso_correlation}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### MLP Regressor\n",
    "\n",
    "Having tried several models without success, we finally decided to use a neural network to do the job. In order to find the best layer configuration, we tested two versions of the MLP. Version 1 used a hidden layer structure of (8, 8, 28) and version 2 used a structure of (8, 8, 7, 25). In both versions, we set the activation function to ReLU, the maximum iterations to 5000 and the random state to 1. However, each MLP used a different set of features as well as batch size, alpha and learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**MLP Regressor v1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "selected_features_mlp = [\n",
    "    0,  # jaccard using words\n",
    "    1,  # jaccard using lemmas\n",
    "    2,  # jaccard using NEs\n",
    "    3,  # tf similarity using words\n",
    "    4,  # tf similairty using lemmas\n",
    "    5,  # tf similarity using NEs\n",
    "    6,  # path similarity\n",
    "    7,  # lch similarity\n",
    "    8,  # wup similarity\n",
    "    # 9,  # lin semcor similarity\n",
    "    # 10,  # res semcor similarity\n",
    "    # 11,  # lesk similarity\n",
    "    # 12,  #unigram count using words\n",
    "    13,  #unigram count using lemmas\n",
    "    # 14,  #bigram count using words\n",
    "    # 15,  #bigram jaccard using words\n",
    "    16,  #bigram count using lemmas\n",
    "    # 17,  #bigram jaccard using lemmas\n",
    "    # 18,  #trigram count using words\n",
    "    # 19,  #trigram jaccard using words\n",
    "    20,  #trigram count using lemmas\n",
    "    # 21,  #trigram jaccard using lemmas\n",
    "    22,  #synnonyms\n",
    "    23  #length difference using lemmas\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "best_nn_corr = 0\n",
    "best_mlp = None\n",
    "best_bs = None\n",
    "best_alpha = None\n",
    "best_lr = None\n",
    "if optimize==1:\n",
    "    for bs in np.arange(150, 160):\n",
    "        for a in np.linspace(1e-2, 1e-1, 20):\n",
    "            for lr in np.linspace(1e-2, 1e-1, 20):\n",
    "                mlp_regr = MLPRegressor((8, 8, 28), activation='relu', max_iter=5000, random_state=1, batch_size=bs,\n",
    "                                        alpha=a, learning_rate_init=lr)\n",
    "                mlp_regr.fit(x_train[:, selected_features_mlp], y_train)\n",
    "                nn_pred = mlp_regr.predict(x_test[:, selected_features_mlp])\n",
    "    \n",
    "                nn_correlation = pearsonr(nn_pred, y_test)[0]\n",
    "                if best_nn_corr < nn_correlation:\n",
    "                    best_nn_corr = nn_correlation\n",
    "                    best_mlp = mlp_regr\n",
    "                    best_bs = bs\n",
    "                    best_alpha = a\n",
    "                    best_lr = lr\n",
    "    \n",
    "    print(f'Best params: batch_size={best_bs}, alpha={best_alpha}, learning_rate_init={best_lr}')\n",
    "    print(f'Pearson correlation using MLP v1: {best_nn_corr}')\n",
    "    \n",
    "    if best_nn_corr > 0.7562:\n",
    "        dump(best_mlp, 'mlp_regr.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation using MLP v1: 0.755952149393855\n"
     ]
    }
   ],
   "source": [
    "# Best MLP regressor found for this hidden layers structure\n",
    "if optimize==1:\n",
    "    mlp_regr_1 = MLPRegressor((8, 8, 28), activation='relu', max_iter=5000, random_state=1, batch_size=best_bs,\n",
    "                              alpha=best_alpha, learning_rate_init=best_lr)\n",
    "    mlp_regr_1.fit(x_train[:, selected_features_mlp], y_train)\n",
    "    mlp_pred_1 = mlp_regr_1.predict(x_test[:, selected_features_mlp])\n",
    "\n",
    "    mlp_correlation_1 = pearsonr(mlp_pred_1, y_test)[0]\n",
    "    print(f'Pearson correlation using MLP v1: {mlp_correlation_1}')\n",
    "\n",
    "else:\n",
    "    mlp_regr_1 = MLPRegressor((8, 8, 28), activation='relu', max_iter=5000, random_state=1, batch_size=154,\n",
    "                              alpha=0.06210526315789474, learning_rate_init=0.09526315789473684)\n",
    "    mlp_regr_1.fit(x_train[:, selected_features_mlp], y_train)\n",
    "    mlp_pred_1 = mlp_regr_1.predict(x_test[:, selected_features_mlp])\n",
    "\n",
    "    mlp_correlation_1 = pearsonr(mlp_pred_1, y_test)[0]\n",
    "    print(f'Pearson correlation using MLP v1: {mlp_correlation_1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**MLP Regressor v2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "selected_features_mlp_2 = [\n",
    "    0,  # jaccard using words\n",
    "    1,  # jaccard using lemmas\n",
    "    2,  # jaccard using NEs\n",
    "    3,  # tf similarity using words\n",
    "    4,  # tf similairty using lemmas\n",
    "    5,  # tf similarity using NEs\n",
    "    6,  # path similarity\n",
    "    7,  # lch similarity\n",
    "    8,  # wup similarity\n",
    "    # 9,  # lin semcor similarity\n",
    "    # 10,  # res semcor similarity\n",
    "    # 11,  # lesk similarity\n",
    "    # 12,  #unigram count using words\n",
    "    13,  #unigram count using lemmas\n",
    "    # 14,  #bigram count using words\n",
    "    # 15,  #bigram jaccard using words\n",
    "    16,  #bigram count using lemmas\n",
    "    # 17,  #bigram jaccard using lemmas\n",
    "    # 18,  #trigram count using words\n",
    "    # 19,  #trigram jaccard using words\n",
    "    20,  #trigram count using lemmas\n",
    "    # 21,  #trigram jaccard using lemmas\n",
    "    # 22,  #synnonyms\n",
    "    23  #length difference using lemmas\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "best_nn_corr = 0\n",
    "best_mlp = None\n",
    "best_bs = None\n",
    "best_alpha = None\n",
    "best_lr = None\n",
    "if optimize==1:\n",
    "    for bs in np.arange(184, 199):\n",
    "        for a in np.linspace(8e-5, 1e-4, 20):\n",
    "            for lr in np.linspace(8e-3, 1e-2, 20):\n",
    "                mlp_regr = MLPRegressor((8, 8, 7, 25), activation='relu', max_iter=5000, random_state=1, batch_size=bs,\n",
    "                                        alpha=a, learning_rate_init=lr)\n",
    "                mlp_regr.fit(x_train[:, selected_features_mlp_2], y_train)\n",
    "                mlp_pred = mlp_regr.predict(x_test[:, selected_features_mlp_2])\n",
    "    \n",
    "                nn_correlation = pearsonr(mlp_pred, y_test)[0]\n",
    "                if best_nn_corr < nn_correlation:\n",
    "                    best_nn_corr = nn_correlation\n",
    "                    best_mlp = mlp_regr\n",
    "                    best_bs = bs\n",
    "                    best_alpha = a\n",
    "                    best_lr = lr\n",
    "    \n",
    "    print(f'Best params: batch_size={best_bs}, alpha={best_alpha}, learning_rate_init={best_lr}')\n",
    "    print(f'Pearson correlation using MLP v2: {best_nn_corr}')\n",
    "    \n",
    "    if best_nn_corr > 0.7562:\n",
    "        dump(best_mlp, 'mlp_regr_2.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation using MLP v2: 0.7676731904156743\n"
     ]
    }
   ],
   "source": [
    "# Best MLP regressor found for this hidden layers structure\n",
    "if optimize==1:\n",
    "    mlp_regr_2 = MLPRegressor((8, 8, 7, 25), activation='relu', max_iter=5000, random_state=1, batch_size=best_bs,\n",
    "                              alpha=best_alpha, learning_rate_init=best_lr)\n",
    "    mlp_regr_2.fit(x_train[:, selected_features_mlp_2], y_train)\n",
    "    mlp_pred_2 = mlp_regr_2.predict(x_test[:, selected_features_mlp_2])\n",
    "    \n",
    "    mlp_correlation_2 = pearsonr(mlp_pred_2, y_test)[0]\n",
    "    print(f'Pearson correlation using MLP v2: {mlp_correlation_2}')\n",
    "else:    \n",
    "    mlp_regr_2 = MLPRegressor((8, 8, 7, 25), activation='relu', max_iter=5000, random_state=1, batch_size=185,\n",
    "                              alpha=9.052631578947369e-05, learning_rate_init=0.00968421052631579)\n",
    "    mlp_regr_2.fit(x_train[:, selected_features_mlp_2], y_train)\n",
    "    mlp_pred_2 = mlp_regr_2.predict(x_test[:, selected_features_mlp_2])\n",
    "\n",
    "    mlp_correlation_2 = pearsonr(mlp_pred_2, y_test)[0]\n",
    "    print(f'Pearson correlation using MLP v2: {mlp_correlation_2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation using the average between MLP v1 and MLP v2: 0.7701330037075897\n"
     ]
    }
   ],
   "source": [
    "avg_pred = mlp_pred_1 + mlp_pred_2\n",
    "\n",
    "avg_correlation = pearsonr(avg_pred, y_test)[0]\n",
    "print(f'Pearson correlation using the average between MLP v1 and MLP v2: {avg_correlation}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Work process\n",
    "\n",
    "First, we started by implementing all the pre-processing functions and metrics we had used during the practical exercises, such as the tokenization and lemmatization for the pre-processing and the Jaccard and lesk similarities. In addition, we added contraction expansion and the cosine similarity. Then we proceeded to choose the model to predict the gold standard. However, were not sure which was the best model to use. Thus, we decided to try with three different models (i.e. Random Forest, KNN and SVR) and select the best one. Among the three, the one giving the best results was the SVR with a correlation of **0.7010**. However, this was not good enough.\n",
    "\n",
    "After some thinking, we decided to add n-gram similarities, which we thought would boost our results. In fact, we were able to slightly improve all three models with only these additions. For example, the correlation obtained using the Random Forest went from **0.5523** to **0.6381**. Nevertheless, we still did not achieve our goal of 0.7562.\n",
    "\n",
    "Since we thought that we could not further improve our current models, we decided to try with two more, being Lasso and Multilayer perceptrons. The Lasso regressor was achieving similar results to our previous models. However, we noticed that the MLP model performed quite well in comparison to the other models. Thus, we decided to select the MLP as our final model and try to improve it to achieve the goal correlation.\n",
    "\n",
    "The next step that we took was to add the synonyms similarity and the length difference as new metrics, and the conversion of numbers to words. In addition, we added some code to tune the hyperparameters of the models. With this, the MLP v1 achieved a Pearson correlation of **0.7648**, surpassing our goal.\n",
    "\n",
    "The final step we did to see if we could further improve our results was to add the cosine similarity using NEs and delete the Lin and Resnik similarities using the brown IC since we were already using them with semcor. Surprisingly, doing these small changes boosted the results of all the models considerably. The most noticeable improvement was for the SVR which achieved a correlation of **0.7632**, surpassing the goal correlation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Results\n",
    "We were able to create three different models which obtained a Pearson correlation above **0.7562**. The SVR model with a correlation coefficient of **0.7632**. The MLP Regressor v2 with a correlation coefficient of **0.7745**. And the best one, the MLP Regressor v1 with a correlation coefficient of **0.7814**.\n",
    "\n",
    "Although all three models already obtained correlations which are better than the results from the 10th participants in the SemEval 2012, we observed that by using the average predictions of the MLP v1 and MPL v2 we achieved even better results, obtaining a correlation of **0.7871**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 4. Conclusions\n",
    "\n",
    "In this work we have been able to apply the knowledge obtained through the different practical excercises done during the course. Although the techniques we have learnt and applied are quite simple in general, they have proven useful to achieve the goal of this project.\n",
    "\n",
    "We consider that we have achieved our initial goal with very good results since we surpassed objective Pearson correlation by almost **0.02** points. This might not seem a great improvement, but we have to keep in mind that achieving a Pearson correlation over **0.7** was quite challenging and that the changes over that threshold usually were minimal when adding new metrics or changing the models.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Lab05-Santiago-del-Rey-Juarez_Nikita-Belooussov.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "56b22a985f18d44d50171c67439d384ccb9cd51faf15dc17dcf099ae374960d9"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
